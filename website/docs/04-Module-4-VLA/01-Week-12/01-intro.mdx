---
sidebar_position: 1
title: 1. Vision-Language-Action
description: VLA Architecture
---

# Vision-Language-Action (VLA)

## The Concept
Traditional robotics pipeline:
`Perception -> State Estimation -> Planning -> Control`

VLA pipeline:
`Image + Text Prompt -> VLA Model -> Robot Action`

## Models
*   **RT-2 (Google)**: Robotic Transformer.
*   **OpenVLA**: Open source alternative.

These models understand semantic commands like "Pick up the plush toy" or "Move the spoon near the bowl".
